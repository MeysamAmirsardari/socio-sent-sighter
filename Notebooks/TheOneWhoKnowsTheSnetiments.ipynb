{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installations:"
      ],
      "metadata": {
        "id": "OwTyM_pizVvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiL13kCEzk8m",
        "outputId": "66965e98-d30d-4c16-e96c-e72d2da054ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports:"
      ],
      "metadata": {
        "id": "BYc9_FI1zleI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch_geometric.data import Data"
      ],
      "metadata": {
        "id": "RPcIwg8szoQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import copy as cp\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.data import DataLoader, DataListLoader\n",
        "from torch_geometric.nn import DataParallel\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import global_mean_pool, GATConv"
      ],
      "metadata": {
        "id": "keQRWnHx2jvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the inputs:"
      ],
      "metadata": {
        "id": "ZAzVFIAmzqlJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXBeS2U-vsUH",
        "outputId": "daef3889-b8c7-44ea-d425-35039714bc34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "688096910217879554\n",
            "688437279405305856\n",
            "688110059553861634\n",
            "688281442162352128\n",
            "688441130271289350\n",
            "688147918113538049\n",
            "688502260779843587\n",
            "688461902821855232\n"
          ]
        }
      ],
      "source": [
        "data_dirs = ['twitter15', 'twitter16']\n",
        "\n",
        "label_file_path = 'sentiments.txt' #'label.txt'\n",
        "source_tweets_file_path = 'source_tweets.txt'\n",
        "tree_file_dir = 'tree'\n",
        "root_path = '/content/drive/MyDrive/retweet_cascade'\n",
        "\n",
        "num_features = 1\n",
        "\n",
        "graph_list = []\n",
        "labels = []\n",
        "\n",
        "\n",
        "for data_dir in data_dirs:\n",
        "    dir_path = os.path.join(root_path, data_dir)\n",
        "\n",
        "    for file_name in os.listdir(os.path.join(dir_path, tree_file_dir)):\n",
        "        if not file_name.endswith('.txt'):\n",
        "            continue\n",
        "\n",
        "        tweet_id = file_name[:-4]\n",
        "        if len(tweet_id) > 18:\n",
        "                      print(tweet_id[:18])\n",
        "                      tweet_id = tweet_id[:18]\n",
        "\n",
        "        edge_list = []\n",
        "        with open(os.path.join(dir_path, tree_file_dir, file_name)) as f:\n",
        "            for line in f:\n",
        "                parent, child = line.strip().split('->')\n",
        "                parent, child = parent.replace(\"'\", \"\").strip(), child.replace(\"'\", \"\").strip()\n",
        "                parent = parent.replace(\"ROOT\", str(tweet_id))\n",
        "\n",
        "                edge_list.append([int(parent.split(',')[1]), int(child.split(',')[1])])\n",
        "\n",
        "        label = -1\n",
        "        with open(os.path.join(dir_path, label_file_path)) as f:\n",
        "            for line in f:\n",
        "                if line.startswith(tweet_id):\n",
        "                    label = int(line.strip().split(':')[1])\n",
        "                    labels.append(label)\n",
        "                    break\n",
        "\n",
        "        # features = torch.zeros((1, num_features))\n",
        "        # with open(os.path.join(dir_path, source_tweets_file_path)) as f:\n",
        "        #     for line in f:\n",
        "        #         if line.startswith(tweet_id):\n",
        "        #             cols = line.strip().split('\\t')\n",
        "        #             features[0, 0] = int(cols[1])  # number of followers\n",
        "        #             features[0, 1] = int(cols[2])  # number of friends\n",
        "        #             features[0, 2] = float(cols[3])  # ratio of followers and friends\n",
        "        #             features[0, 3] = int(cols[4])  # number of history tweets\n",
        "        #             features[0, 4] = int(cols[5])  # registration time (year)\n",
        "        #             features[0, 5] = int(cols[6])  # whether verified account or not\n",
        "        #             break\n",
        "        features = torch.ones((1, num_features))\n",
        "\n",
        "        edge_index = torch.tensor(edge_list).t().contiguous()\n",
        "        x = features.repeat(len(edge_list) + 1, 1)\n",
        "        data = Data(x=x, edge_index=edge_index, y=label)\n",
        "\n",
        "        graph_list.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(graph_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okKCUjcYHEfA",
        "outputId": "8f2d754c-4930-4857-fcf9-86e7812a3a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[138, 1], edge_index=[2, 137], y=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(graph_list, 'retweet_cascade_dataset.pt')"
      ],
      "metadata": {
        "id": "a5b9z1Pu705H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Craeting the Dataset:"
      ],
      "metadata": {
        "id": "VoG7eHaR1Kdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch_geometric.data import Data\n",
        "\n",
        "# epoch_len = 120\n",
        "# land_mark_num = 18\n",
        "# len = df.shape[0]-1\n",
        "# overlap = 0.5\n",
        "# graph_list = []\n",
        "# order = []\n",
        "# count = 0\n",
        "# step = 10\n",
        "\n",
        "# #edge_index, edge_attr = set_edges(epoch_len, land_mark_num)\n",
        "\n",
        "# for i in range(1, len-epoch_len, step):\n",
        "#   x = set_nodes(norm_Xs, norm_Ys, CLs, i, land_mark_num, epoch_len)\n",
        "#   data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "#   graph_list.append(data)\n",
        "#   count = count + 1\n",
        "#   order.append((count, i))\n",
        "\n",
        "# graph_num = count"
      ],
      "metadata": {
        "id": "8NPG_7rD1KD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Saving the dataset:\n"
      ],
      "metadata": {
        "id": "3IQj39cZ3McO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "loader = DataLoader(graph_list, batch_size=16)\n",
        "torch.save(loader, '/content/drive/MyDrive/retweets_loader.pth')"
      ],
      "metadata": {
        "id": "apYBrUqV3BUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "from torch_geometric.data import Dataset, download_url\n",
        "\n",
        "root = '/content/drive/MyDrive/Test_loader.pth'\n",
        "\n",
        "class Dataset1(Dataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.processed_file_names)\n",
        "\n",
        "    def get(self, idx):\n",
        "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "        return data"
      ],
      "metadata": {
        "id": "KmkDjaZPA2ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the model:"
      ],
      "metadata": {
        "id": "Vfcx62gl3SVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* some more imports:"
      ],
      "metadata": {
        "id": "NC0qMU523ZwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv, VGAE\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GAE, VGAE, GCNConv\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "GeJbZXIC3PVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNSentiment(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, concat=True):\n",
        "      super(GCNSentiment, self).__init__()\n",
        "\n",
        "      self.num_features = input_dim\n",
        "      self.num_classes = output_dim\n",
        "      self.nhid = hidden_dim\n",
        "      self.concat = concat\n",
        "\n",
        "      self.conv1 = GATConv(self.num_features, self.nhid * 2)\n",
        "      self.conv2 = GATConv(self.nhid * 2, self.nhid * 2)\n",
        "\n",
        "      self.fc1 = Linear(self.nhid * 2, self.nhid)\n",
        "\n",
        "      if self.concat:\n",
        "        self.fc0 = Linear(self.num_features, self.nhid)\n",
        "        self.fc1 = Linear(self.nhid * 2, self.nhid)\n",
        "      self.fc2 = Linear(self.nhid, self.num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "      x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "      x = F.selu(self.conv1(x, edge_index))\n",
        "      x = F.selu(self.conv2(x, edge_index))\n",
        "      x = F.selu(global_mean_pool(x, batch))\n",
        "      x = F.selu(self.fc1(x))\n",
        "      x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "      if self.concat:\n",
        "        news = torch.stack([data.x[(data.batch == idx).nonzero().squeeze()[0]] for idx in range(data.num_graphs)])\n",
        "        news = F.relu(self.fc0(news))\n",
        "        x = torch.cat([x, news], dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "      x = F.log_softmax(self.fc2(x), dim=-1)\n",
        "      return x"
      ],
      "metadata": {
        "id": "4Yg_7MG63dJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model:"
      ],
      "metadata": {
        "id": "cTjFKyxP3drK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "input_dim = 1\n",
        "hidden_dim = 16\n",
        "output_dim = 3\n",
        "batch_size = 16\n",
        "epoch_num = 100\n",
        "\n",
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "dataloader = DataLoader(graph_list, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = GCNSentiment(input_dim, hidden_dim, output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epoch_num):\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch)\n",
        "        loss = F.nll_loss(out, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * batch.num_graphs\n",
        "    print(\"Epoch \", epoch, \" loss: \", total_loss / len(graph_list)) # note!\n",
        "\n",
        "\n",
        "model.eval()\n",
        "pred_y = []\n",
        "true_y = []\n",
        "\n",
        "for batch in dataloader:\n",
        "    batch = batch.to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        pred = out.argmax(dim=-1)\n",
        "        pred_y.append(pred.cpu().numpy())\n",
        "        true_y.append(batch.y.cpu().numpy())\n",
        "\n",
        "pred_y = np.concatenate(pred_y, axis=0)\n",
        "true_y = np.concatenate(true_y, axis=0)\n",
        "\n",
        "f1 = f1_score(true_y, pred_y, average='macro')\n",
        "print(\"F1 score: \", f1)"
      ],
      "metadata": {
        "id": "gOWaWWAZ3hGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's watch the model!"
      ],
      "metadata": {
        "id": "l8ICm-mT_9BX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from tqdm import tqdm\n",
        "from sklearn.manifold import TSNE"
      ],
      "metadata": {
        "id": "EGqIWORUA_jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(dataset):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        data = dataset[0]\n",
        "        embeddings = model.conv2(F.selu(model.conv1(data.x, data.edge_index)), data.edge_index)\n",
        "        return embeddings.cpu().numpy()\n",
        "\n",
        "\n",
        "dataset = dataset \n",
        "last_layer_embeddings = get_embeddings(dataset)\n",
        "\n",
        "\n",
        "tsne = TSNE(n_components=2)\n",
        "embeddings_2d = tsne.fit_transform(last_layer_embeddings)\n",
        "\n",
        "colors = ['red', 'green', 'blue']\n",
        "labels = labels\n",
        "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=labels, cmap=plt.colors.ListedColormap(colors))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2s8jANYdACa4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}