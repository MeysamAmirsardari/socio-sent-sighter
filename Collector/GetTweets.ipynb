{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import datetime \n",
    "from twitter_authentication import bearer_token\n",
    "from gmail_info import gmail_pass, gmail_user\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import smtplib\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('data') == False:\n",
    "    os.mkdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('logs') == False:\n",
    "    os.mkdir('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open('./logs/log_btc_train.txt', 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTC Train Set 2017 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_name = 'btc_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_name = \"BTC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_str = '2017-01-14'\n",
    "end_str =   '2020-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.strptime(start_str, \"%Y-%m-%d\")\n",
    "end =   datetime.datetime.strptime(end_str, \"%Y-%m-%d\")\n",
    "diff = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list = str(diff).split(' ')\n",
    "num_hours = int(diff_list[0]) * 24 + 1\n",
    "print(num_hours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = start\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = []\n",
    "for i in range(0, num_hours):\n",
    "    date_str = date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    date_list.append(date_str)\n",
    "    date += datetime.timedelta(hours=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = date_list [0]\n",
    "end_date = date_list[len(date_list) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (start_date)\n",
    "print (end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for j in range(0, len(date_list) - 1):\n",
    "    \n",
    "    count = count + 1\n",
    "    \n",
    "    f= open('./logs/log_btc_train.txt', 'a')\n",
    "    f.write(\"\\n\") \n",
    "    f.write(date_list[j] + \"\\n\")\n",
    "    f.write(date_list[j+1] + \"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                    query = '#btc OR #bitcoin OR #bitcointrading -is:retweet lang:en',\n",
    "                                    user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                    tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                    expansions = 'author_id',\n",
    "                                    start_time = date_list [j],\n",
    "                                    end_time = date_list [j+1],\n",
    "                                    max_results=10,  \n",
    "                                    limit=25):\n",
    "        \n",
    "        time.sleep(1)\n",
    "        tweets_list.append(response)\n",
    "        \n",
    "    \n",
    "    if count % 24 == 0:\n",
    "        \n",
    "        f= open('./logs/log_btc_train.txt', 'a')\n",
    "        f.write(\"output to csv\")\n",
    "        f.close()\n",
    "        \n",
    "        path = './data/'+ asset_name + '__' + date_list[j][0:10] + '.csv'\n",
    "        \n",
    "        result = []\n",
    "        user_dict = {}\n",
    "        \n",
    "        # Loop through each response object\n",
    "        for response in tweets_list:\n",
    "            # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "            for user in response.includes['users']:\n",
    "                user_dict[user.id] = {'username': user.username, \n",
    "                                    'followers': user.public_metrics['followers_count'],\n",
    "                                    'tweets': user.public_metrics['tweet_count'],\n",
    "                                    'description': user.description,\n",
    "                                    'location': user.location\n",
    "                                    }\n",
    "            for tweet in response.data:\n",
    "                # For each tweet, find the author's information\n",
    "                author_info = user_dict[tweet.author_id]\n",
    "                # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "                result.append({'author_id': tweet.author_id, \n",
    "                            'username': author_info['username'],\n",
    "                            'author_followers': author_info['followers'],\n",
    "                            'author_tweets': author_info['tweets'],\n",
    "                            'author_description': author_info['description'],\n",
    "                            'author_location': author_info['location'],\n",
    "                            'text': tweet.text,\n",
    "                            'created_at': tweet.created_at,\n",
    "                            'retweets': tweet.public_metrics['retweet_count'],\n",
    "                            'replies': tweet.public_metrics['reply_count'],\n",
    "                            'likes': tweet.public_metrics['like_count'],\n",
    "                            'quote_count': tweet.public_metrics['quote_count']\n",
    "                            })\n",
    "\n",
    "        # Change this list of dictionaries into a dataframe\n",
    "        df = pd.DataFrame(result)\n",
    "        \n",
    "        df.to_csv(path)\n",
    "        \n",
    "        tweets_list = []\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_from = gmail_user\n",
    "# to = ['spencerd.king@gmail.com', 'sdk81722@uga.edu']\n",
    "# subject = 'Old Tweet Gathering Is Done: ' + data_set_name + ' !'\n",
    "# body = 'The ' + data_set_name + ' set is downloaded and ready for use! \\n\\nData set date range: ' + start_date + ' to ' + end_date\n",
    "\n",
    "# email_text = \"\"\"\\\n",
    "# From: %s\n",
    "# To: %s\n",
    "# Subject: %s\n",
    "\n",
    "# %s\n",
    "# \"\"\" % (sent_from, \", \".join(to), subject, body)\n",
    "\n",
    "# try:\n",
    "#     smtp_server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "#     smtp_server.login(gmail_user, gmail_pass)\n",
    "#     smtp_server.sendmail(sent_from, to, email_text)\n",
    "#     smtp_server.close()\n",
    "#     print (\"Email sent successfully!\")\n",
    "# except Exception as ex:\n",
    "#     print (\"Something went wrongâ€¦.\",ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Notes\n",
    "\n",
    "1. Set up email notifications if linode will let you\n",
    "2. Find a way to run program in the background\n",
    "    Most likely will have to just make it into a script and run in back ground with nohup ... &\n",
    "    https://stackoverflow.com/questions/57664547/long-running-jupyter-notebook-lab\n",
    "    \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d100e7957bc88683fb6d449d1832e5831d5f805d77b57e14790aec5169fed04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
